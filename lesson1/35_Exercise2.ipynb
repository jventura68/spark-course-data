{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"accidentes\"\n",
    "master = \"local[*]\"\n",
    "spark = (SparkSession.builder\n",
    "    .master(master)\n",
    "    .config(\"spark.driver.cores\", 1)\n",
    "    .appName(app_name)\n",
    "    .getOrCreate() )\n",
    "sc = spark.sparkContext\n",
    "print ('SparkContext created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga el fichero en el vector lines2 leyendolo desde la web\n",
    "import urllib.request\n",
    "url = 'https://www.gutenberg.org/files/76/76-0.txt' #huckleberry.txt en el proyecto Gutemberg\n",
    "response = urllib.request.urlopen(url)\n",
    "data = response.read()\n",
    "data = data.decode('utf-8')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = data.split('\\n')\n",
    "len (lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea el RDD a partir de lines\n",
    "book = sc.parallelize(lines)\n",
    "book.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    \"\"\"\n",
    "    Remove \\ufeff\\r characters\n",
    "    Remove \\t \\n \\r\n",
    "    Remove additional characters\n",
    "    \"\"\"\n",
    "    return line.replace('\\ufeff\\r', '').\\\n",
    "        replace('\\t', ' ').replace('\\n', '').replace('\\r', '').\\\n",
    "        replace('(', '').replace(')', '').replace(\"'\", '').\\\n",
    "        replace('\"', '').replace(',', ''). replace('.', '').\\\n",
    "        replace('*', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove characters and empty lines\n",
    "cleaned_book = book.map(lambda x: clean_line (x))\\\n",
    "                   .filter (lambda x: x != '')\n",
    "cleaned_book.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_book.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_tokenize(line):\n",
    "    \"\"\"\n",
    "    Normalize: lowercase\n",
    "    tokenize: split in tokens\n",
    "    \"\"\"\n",
    "    return re.sub('\\s+', ' ', line).strip().lower().split(' ')\n",
    "tokens = cleaned_book.flatMap (normalize_tokenize)\n",
    "tokens.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tokens = tokens.filter (lambda s: len(s) > 3)\n",
    "reduced_tokens.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tokens.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = reduced_tokens.map (lambda x: (x, 1))\n",
    "counts.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_counts = counts.reduceByKey (\n",
    "                    lambda accumulator , value : accumulator + value)\n",
    "reduced_counts.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered by natural key (word)\n",
    "reduced_counts.takeOrdered(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered by frequency\n",
    "reduced_counts.takeOrdered (4, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse order by frequency\n",
    "reduced_counts.takeOrdered (8, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse order by frequency, other way\n",
    "reduced_counts.top (8, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude top n words with top high frequecy but meaningless\n",
    "huckleberry_book = reduced_counts.filter(\n",
    "          lambda x: x[1] < 500)\n",
    "huckleberry_book.takeOrdered (8, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_url = 'https://www.gutenberg.org/files/2265/2265.txt'\n",
    "response = urllib.request.urlopen(hamlet_url)\n",
    "data = response.read().decode('utf-8').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates a RDD for hamlet book\n",
    "Removes characters, empty lines\n",
    "Tokenize\n",
    "Removes stop words\n",
    "Counts frequecy\n",
    "'''\n",
    "shakespeare_book = sc.parallelize (data).\\\n",
    "      map (clean_line).\\\n",
    "      filter (lambda x: x != '').\\\n",
    "      flatMap (normalize_tokenize).\\\n",
    "      filter (lambda x: len(x) > 3).\\\n",
    "      map (lambda x: (x, 1)).\\\n",
    "      reduceByKey (\n",
    "          lambda accum, val: accum + val)\n",
    "shakespeare_book.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_book.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_book.takeOrdered (4, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Perform join operation to find out what words\n",
    "are used in both books\n",
    "'''\n",
    "common_words = huckleberry_book.join (shakespeare_book)\n",
    "common_words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordering by word\n",
    "common_words.takeOrdered (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words.takeOrdered (8, key=lambda x: -x[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordering by the sum of the frequencies in both books\n",
    "common_words.takeOrdered (8, key=lambda x: x[1][0] + x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words.top (8, key=lambda x: x[1][0] + x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words.takeOrdered (8, key=lambda x: -1 * (x[1][0] + x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words that are unique to huckleberry_book\n",
    "hamlet_book = shakespeare_book\n",
    "unique_huckleberry_book = huckleberry_book.\\\n",
    "    leftOuterJoin (hamlet_book).\\\n",
    "        filter (lambda x: x[1][1] is None).\\\n",
    "        map (lambda x: x[0])\n",
    "unique_huckleberry_book.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_huckleberry_book.take (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words that are unique to hamlet_book\n",
    "unique_hamlet_book = hamlet_book.\\\n",
    "    leftOuterJoin (huckleberry_book).\\\n",
    "        filter (lambda x: x[1][1] is None).\\\n",
    "        map (lambda x: x[0])\n",
    "unique_hamlet_book.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_hamlet_book.take (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words that are unique to hamlet_book using rightOuterJoin ????\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
