{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"accidentes\"\n",
    "master = \"local[*]\"\n",
    "spark = (SparkSession.builder\n",
    "    .master(master)\n",
    "    .config(\"spark.driver.cores\", 1)\n",
    "    .appName(app_name)\n",
    "    .getOrCreate() )\n",
    "sc = spark.sparkContext\n",
    "print ('SparkContext created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def getLinesFromUrl(url:str):\n",
    "    \"\"\"\n",
    "    Downloads content from a url and\n",
    "    creates a text based RDD\n",
    "    \"\"\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    lines = data.split('\\n')\n",
    "    # creates a RDD for the book\n",
    "    return sc.parallelize(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huckleberry_lines = getLinesFromUrl ('https://www.gutenberg.org/files/76/76-0.txt')\n",
    "hamlet_lines = getLinesFromUrl ('https://www.gutenberg.org/files/2265/2265.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def getRDDWords(book):\n",
    "    def clean_line(line):\n",
    "        \"\"\"\n",
    "        Remove \\ufeff\\r characters\n",
    "        Remove \\t \\n \\r\n",
    "        Remove additional characters\n",
    "        \"\"\"\n",
    "        return line.replace('\\ufeff\\r', '').\\\n",
    "            replace('\\t', ' ').replace('\\n', '').replace('\\r', '').\\\n",
    "            replace('(', '').replace(')', '').replace(\"'\", '').\\\n",
    "            replace('\"', '').replace(',', ''). replace('.', '').\\\n",
    "            replace('*', '')\n",
    "\n",
    "    def normalize_tokenize(line):\n",
    "        \"\"\"\n",
    "        Normalize: lowercase\n",
    "        tokenize: split in tokens\n",
    "        \"\"\"\n",
    "        return re.sub('\\s+', ' ', line).strip().lower().split(' ')\n",
    "\n",
    "    return book.map(lambda x: clean_line(x)).\\\n",
    "        filter(lambda x: x != '').flatMap(normalize_tokenize) #.\\\n",
    "        #filter(lambda x: len(x)>3).\\\n",
    "        #map (lambda x: (x, 1)).\\\n",
    "        #reduceByKey (lambda x, y: x + y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huckleberry_words = getRDDWords (huckleberry_lines)\n",
    "huckleberry_counts = huckleberry_words.map (lambda x: (x, 1)).\\\n",
    "                                       reduceByKey (lambda x, y: x + y)\n",
    "print ('Tokens: {} / First {}'.format (huckleberry_counts.count(), huckleberry_counts.take(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_words = getRDDWords (hamlet_lines)\n",
    "hamlet_counts = hamlet_words.map (lambda x: (x, 1)).\\\n",
    "                                       reduceByKey (lambda x, y: x + y)\n",
    "print ('Tokens: {} / First {}'.format (hamlet_counts.count(), hamlet_counts.take(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular la media de la longitud de palabra\n",
    "---\n",
    "<br>\n",
    "puede hacer uso de la funcion [RDD].reduce(f)\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average length word. Reduce function\n",
    "import operator\n",
    "\n",
    "huckleberry_words.map (lambda x: len(x)).reduce(operator.add)/ huckleberry_words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Como se haría con el RDD hucdkleberry_counts()?\n",
    "huckleberry_counts.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huckleberry_counts.map (lambda x: len(x[0])*x[1]).sum()/huckleberry_counts.values().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "huckleberry_words.map (lambda x: len(x)).sum()/ huckleberry_words.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huck_word_len_mean = huckleberry_words.map (lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "El método aggregate tiene un valor base sobre el que se hacen las agregaciones\n",
    "\n",
    "Después se le define una función de transformación de los elementos del RDD en tuplas\n",
    "en las que el primer elemento es la long. acumulada y el segundo el contador de palabras.\n",
    "A la función lambda le llega como primer parámetro el acumulador, y como segundo los \n",
    "elementos del RDD 'huckleberry_words'\n",
    "\n",
    "Por último definimos otra función que hace un merge de todas las tuplas\n",
    "'''#El método aggregate tiene un valor base: (0,0)\n",
    "#\n",
    "sumChars,numWords = huckleberry_words.aggregate ( (0,0),\n",
    "                           lambda ac, v: (ac[0]+len(v), ac[1]+1),\n",
    "                           lambda item1, item2: (item1[0]+item2[0], item1[1]+item2[1]))\n",
    "print ('La media por palabra es {}'.format (sumChars/numWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desviación estándar\n",
    "---\n",
    "$\\Large\\text{DE} = \\sqrt{\\dfrac{\\sum\\limits_{}^{}{{\\lvert x-\\mu\\rvert^2}}}{N}}$\n",
    "\n",
    "### donde: \n",
    "* $\\text{x}$ son los elementos de la población, cada una de las longitudes\n",
    "* $\\mu$ es la media de la población, en este caso la longitud media de las palabras\n",
    "* $\\text{N}$ es el número de elementos de la población, la cantidad de palabras\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt(huckleberry_words.map (lambda x: (len(x)-huck_word_len_mean)**2).sum()/huckleberry_words.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huckleberry_words.map(lambda x:len(x)).stdev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 palabras más frecuentes\n",
    "---\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huckleberry_counts.top(5, key=lambda k: k[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huckleberry_counts.takeOrdered (5,key=lambda k:-k[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimina el contexto spark\n",
    "#Debe ser la última sentencia\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
